{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Machine Learning Techniques \n",
    "\n",
    "Marta Sestelo (msestelo@gradiant.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "\n",
    "1. [Linear Regression Models](#lm)\n",
    "2. [Generalized Linear Models](#glm)\n",
    "3. [Generalized Additive Models](#gam)\n",
    "4. [Tree-based Method](#trees)\n",
    "    - [Decision trees](#tree)\n",
    "    - [Random Forest](#rf)\n",
    "    - [Gradient Boosting](#gbm)\n",
    "5. [Model Evaluation](#eval)\n",
    "6. [Clustering](#cluster)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, it is necessary to load the required packages. Both `ggplot2`, `dplyr` and `readr` are included in the [`tidyverse`](https://www.tidyverse.org/) package collection, so you can load just this package. \n",
    "\n",
    "Note: in the case you use a jupiter notebook you have to load the packages one by one.\n",
    "\n",
    "The previous packages will be used for a very short exploratory data analysis. For modelling, we are going to use the `mgcv`, `rpart`, `randomForest` and `gbm` packages, aparte de las functions implemented in the `base` package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# library(tidyverse)\n",
    "# For EDA\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(readr)\n",
    "\n",
    "# For modelling\n",
    "library(mgcv)\n",
    "library(rpart)\n",
    "library(randomForest)\n",
    "install.packages(\"gbm\")\n",
    "library(gbm)\n",
    "\n",
    "# More things...\n",
    "install.packages(\"DALEX\")\n",
    "library(DALEX)\n",
    "install.packages(\"rpart.plot\")\n",
    "library(rpart.plot)\n",
    "install.packages(\"Metrics\")\n",
    "library(Metrics)\n",
    "install.packages(\"OptimalCutpoints\")\n",
    "library(OptimalCutpoints)\n",
    "install.packages(\"ROCR\")\n",
    "library(ROCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 8, repr.plot.height = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lm\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "This is one of the most used techniques for assesing the relationship between a set of predictors and the response. There are two main reasons because we want to estimate the coefficiets of a linear model: inference and prediction.\n",
    "\n",
    "The goal of our first use case is to predict the price per square meter of an apartment in Warsaw (Poland) based on selected features such as construction year, surface, floor, number of rooms, district. It should be noted that four of these variables are continuous while the fifth one is a categorical one. Prices are given in Euro. This dataset is available in the `DALEX` package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qplot(y = m2.price, x = district, data = apartments, geom = \"boxplot\", fill = district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qplot(x = surface, y = m2.price, data = apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model <- lm(m2.price ~ surface, data = apartments) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model$coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confint(model, level = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qplot(x = surface, y = m2.price, data = apartments, geom = \"smooth\", method = \"lm\") + geom_point()\n",
    "# plot(apartments$surface, apartments$m2.price)\n",
    "# abline(m1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model <- lm(m2.price ~ ., data = apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels(apartments$district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,3))\n",
    "termplot(lm_model, se = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m3 <- lm(m2.price ~ surface + floor + no.rooms + district, data = apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova(m3, m2) # null model vs full model  test F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(construction.year = 2000, surface = 70, floor = 3, no.rooms = 2, district = \"Srodmiescie\")\n",
    "muhat <- predict(lm_model, newdata = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"glm\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Linear Models\n",
    "\n",
    "`R` makes it very easy to fit a logistic regression model. The function used for this purpose is `glm()` and the fitting process is not so different from the one used in linear regression. \n",
    "\n",
    "Weâ€™ll be working on the Titanic dataset. There are different versions of this dataset freely available online.\n",
    "\n",
    "The dataset is a collection (n = 1309) of data about some of the passengers and the goal here is to predict the survival (either 1 if the passenger survived or 0 if they did not) based on some features such as the sex, the age, the fare of the ticket, etc. (both categorical and continuous variables).  Data frame with the following 14 columns:\n",
    "\n",
    "PassengerId: Passenger ID, Survived: Passenger Survival Indicator, Pclass: Passenger Class, Name: Name, Sex: Sex, Age: Age, SibSp: Number of Siblings/Spouses Aboard, Parch: Number of Parents/Children Aboard,Ticket: Ticket Number, Fare: Passenger Fare, Cabin: Cabin, Embarked: Port of Embarkation, Home.dest: Home destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download.file(\"https://goo.gl/At238b\", \"titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic <- read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_model <- glm(survived ~ sex + age + fare + sibsp, family = binomial(link = \"logit\"), data = titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(glm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will our model tell us about Rose and Jack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if beta positive, odds ratio > 1: increase prob\n",
    "# if beta negative, odds ratio < 1: deacrease prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(coef(glm_model)) # from female to male decreases the probability 92%\n",
    "                    # to increase a year decreases the probability 2%\n",
    "                       # to increase 1 euro increases the probability 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(sex = c(\"female\", \"male\"), age = c(17, 23), fare = c(150, 15), sibsp = c(3, 0))\n",
    "muhat <- predict(glm_model, newdata = df, type = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gam\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Additive Models\n",
    "\n",
    "\n",
    "Coming back to the `apartments` dataset, can the relationship between the prize of the meter square and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?\n",
    "\n",
    "Now it is time to fit a model using a more flexible structure. For this, we can apply the `gam()` function of the `mgcv` package which apply splines to estimate each of the f functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam_model <- gam(m2.price ~ + s(construction.year) + s(surface) + s(floor) + \n",
    "             s(no.rooms, k = 5) + district, data = apartments)\n",
    "# s() Function used in definition of smooth terms within gam model formulae.\n",
    "# k = the dimension of the basis used to represent the smooth term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(gam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(gam_model, pages = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(gam_model, select = 1, shade = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(construction.year = 2000, surface = 70, floor = 3, no.rooms = 2, district = \"Srodmiescie\")\n",
    "muhat <- predict(gam_model, newdata = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(muhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trees\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based-tree\n",
    "\n",
    "We move now to the based-tree methods, particularly, we will focus on decision trees, random forest and gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tree\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Decision tree \n",
    "\n",
    "We start showing how one can apply a decision tree approach. The function `rpart` can run a regression tree if the response variable is numeric, and a classification tree if it is a categorical one. We can see that this technique is a very intuitive and simple approach. Firstly, we carry out the regression analysis taking into account the `apartments` data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model <- rpart(m2.price ~ ., method = \"anova\", data = apartments) # anova is for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpart.plot(tree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(construction.year = 2000, surface = 70, floor = 3, no.rooms = 2, district = \"Srodmiescie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(tree_model, newdata = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we carry out the classification analysis taking into account the `titanic` data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model_titanic <- rpart(survived ~ sex + age + fare + sibsp,\n",
    "                            method = \"class\", data = titanic) # class is for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpart.plot(tree_model_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "\n",
    "In this part, we will explain how apply the random forest technique in practice for regresion and classification. \n",
    "\n",
    "Now, we will create a Random Forest model with default parameters and then we will fine tune the model by changing `mtry` (number of variables randomly sampled at each stage ) and `ntree` (number of trees). By default, number of trees is 500 and number of variables tried at each split is 1 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model <- randomForest(m2.price ~ construction.year + surface + floor + \n",
    "                      no.rooms + district, data = apartments, ntree = 500, mtry = 1)\n",
    "# ntree: number of tree to grow = 1000\n",
    "# mtry:number of variables randomly sample  = 2  (p/3 - regression, sqrt(p) - classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varImpPlot(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(m2.price = 200, construction.year = 2000, surface = 70, floor = 3, no.rooms = 2, \n",
    "                 district = \"Srodmiescie\")\n",
    "apartments2 <- rbind(apartments, df)\n",
    "\n",
    "muhat <- predict(rf_model, newdata = apartments2[1001, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gbm\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "Here we use the `gbm` package, and within it the `gbm()`function in order to fit boosted regression trees to the apartments data set. We run `gbm()` with the option `distribution = \"gaussian\"` since this is a regression problem; if it were a binary classification problem, we would use `distribution = \"bernoulli\"`. The argument `n.trees = 5000` indicates that we want 5000 trees, and the option `interaction.depth = 4` limits the depth of each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model <- gbm(m2.price ~ ., data = apartments, n.trees = 5000, interaction.depth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(gb_model) # is like importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(construction.year = 2000, surface = 70, floor = 3, no.rooms = 2, \n",
    "                 district = \"Srodmiescie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muhat <- predict(gb_model, newdata = df, n.trees = 5000, type = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eval\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "\n",
    "Now, we will split the dataset into train and test set in the ratio 80:20. Firstly, we are going to evaluate the regression model and then the classification ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression problem\n",
    "\n",
    "For the evaluation, we are going to use 1-Fold CV with the Mean Square Error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(30072016)\n",
    "train <- apartments %>% sample_frac(.80)\n",
    "test  <- anti_join(apartments, train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model <- lm(m2.price ~ ., data = train)\n",
    "gam_model <- gam(m2.price ~ + s(construction.year) + s(surface) + s(floor) + \n",
    "â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚ s(no.rooms, k = 5) + district, data = train)\n",
    "tree_model <- rpart(m2.price ~ ., method = \"anova\", data = train) \n",
    "rf_model <- randomForest(m2.price ~ construction.year + surface + floor + \n",
    "â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚no.rooms + district, data = train, ntree = 1000, mtry = 2)\n",
    "gb_model <- gbm(m2.price ~ ., data = train, n.trees = 5000, interaction.depth = 1)\n",
    "\n",
    "muhat_lm <- predict(lm_model, newdata = test)\n",
    "muhat_gam <- predict(gam_model, newdata = test)\n",
    "muhat_tree <- predict(tree_model, newdata = test)\n",
    "muhat_rf <- predict(rf_model, newdata = test)\n",
    "muhat_gb <- predict(gb_model, newdata = test, n.trees = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mse_lm <- mean((test$m2.price - muhat_lm)**2))\n",
    "(mse_gam <- mean((test$m2.price - muhat_gam)**2))\n",
    "(mse_tree <- mean((test$m2.price - muhat_tree)**2))\n",
    "(mse_rf <- mean((test$m2.price - muhat_rf)**2))\n",
    "(mse_gb <- mean((test$m2.price - muhat_gb)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification problem\n",
    "\n",
    "For the evaluation, we are going to use 1-Fold CV with the Mean Square Error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(30072016)\n",
    "titanic2 <- na.omit(titanic[, c(2, 4, 5, 6, 9)])\n",
    "titanic2 <- titanic2  %>% mutate (survived = factor(survived), sex = factor(sex))\n",
    "train <- titanic2 %>% sample_frac(.80)\n",
    "test  <- anti_join(titanic2, train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_model <- glm(survived ~ sex + age + fare + sibsp, family = \"binomial\", data = train)\n",
    "gam_model <- gam(survived ~ sex + s(age) + s(fare) + s(sibsp, k = 7), family = \"binomial\", data = train)\n",
    "tree_model <- rpart(survived ~ sex + age + fare + sibsp, method = \"class\", data = train)\n",
    "rf_model <- randomForest(survived ~ sex + age + fare + sibsp, data = train)\n",
    "gb_model <- gbm(as.numeric(survived)-1 ~ ., data = train, n.trees = 5000, distribution = \"bernoulli\")\n",
    "\n",
    "muhat_glm <- predict(glm_model, newdata = test, type = \"response\")\n",
    "muhat_gam <- predict(gam_model, newdata = test, type = \"response\")\n",
    "muhat_tree <- predict(tree_model, newdata = test)\n",
    "muhat_rf <- predict(rf_model, newdata = test)\n",
    "muhat_gb <- predict(gb_model, newdata = test, n.trees = 1500, type = \"response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For selecting the best model we are going to use the AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(glm_auc <- auc(test$survived, muhat_glm))\n",
    "(gam_auc <- auc(test$survived, muhat_gam))\n",
    "(tree_auc <- auc(test$survived, muhat_tree[, 2]))\n",
    "(rf_auc <- auc(test$survived, as.numeric(muhat_rf)-1))\n",
    "(gb_auc <- auc(test$survived, muhat_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For calculating the confusion matrix we need to obtain the best threshold...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux <- data.frame(muhat = muhat_glm, yreal = test$survived)\n",
    "\n",
    "opt <- optimal.cutpoints(X = \"muhat\", status = \"yreal\", tag.healthy = 0, \n",
    "                         methods = \"Youden\", data = aux, pop.prev = NULL, \n",
    "                         control = control.cutpoints(), ci.fit = FALSE, \n",
    "                         conf.level = 0.95, trace = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred <-ifelse(muhat_glm >= opt$Youden$Global$optimal.cutoff$cutoff, 1, 0)\n",
    "(confusion_matrix <- table(test$survived, pred))\n",
    "(accuracy <- (sum(diag(confusion_matrix)))/sum(confusion_matrix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting the ROC curve..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred <- prediction(as.vector(muhat_glm), test$survived)\n",
    "aux <- performance(pred, \"tpr\", \"fpr\")\n",
    "plot(aux)\n",
    "mtext(paste(\"AUC =\",round(glm_auc, 4)), side = 1, line =-2, col =\"blue\" ,cex=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cluster\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(iris)\n",
    "x <- iris[,-5]\n",
    "y <- iris$Species\n",
    "cl3 <- kmeans(x[, c(1,3)], centers = 3, nstart = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl3$tot.withinss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris  %>% \n",
    "    select(Sepal.Length, Petal.Length)  %>% \n",
    "    qplot(y = Sepal.Length, x = Petal.Length, data = ., geom = \"point\", colour = factor(cl3$cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/><div style=\"text-align: right\">Material mainly based on the book **[The Elements of Statistical Learning: Data Mining, Inference, and Prediction](https://web.stanford.edu/~hastie/ElemStatLearn/)** (Hastie, Tibshirani and Friedman, 2009).</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
